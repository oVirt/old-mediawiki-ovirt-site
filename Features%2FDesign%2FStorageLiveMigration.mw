=Storage Live Migration=
Live block migration is the operation in charge of moving a running VM and its disks from one storage domain to another.

==GUI==
No major gui modifications are required. The action to move a VM from one storage to another should be enabled also when the VM is running, in which case the engine will issue a live block migration.

[[Image:StorageLiveMigrationGUI.png]]

==Pre-Copy, Post-Copy and Mirrored-Snapshot==
* '''Pre-Copy:''' copy all the internal volumes and then live copy the leaf volume, when the task is completed live migrate the VM
** '''Pros:''' safer and simpler to manage in the oVirt engine and VDSM
** '''Cons:''' if the snapshots are no longer needed then a lot of data is copied needlessly.  NB. Not implemented upstream yet
* '''Post-Copy:''' live migrate the VM with a live snapshot to the new domain, copy the internal volumes and when the task is completed switch the leaf backing file
** '''Pros:''' better approach for HA/load balancing
** '''Cons:''' complex management in the oVirt engine and VDSM.  Disk is split across multiple domains
* '''Mirrored-Snapshot:''' mirror a new live snapshot on both source and destination, copy the parent volume to the destination and when completed switch to the new image.
** '''Pros:''' no need to implement cross-domain volume chains in VDSM

Reference: [http://wiki.qemu.org/Features/LiveBlockMigration http://wiki.qemu.org/Features/LiveBlockMigration]

==Post-Copy Execution Diagrams and Description==

[[Image:StorageLiveMigration1.png]]

* '''Note on [3]''': when the SPM finishes the operation it's also responsible to set the 'Snapshot 2 Volume' metadata to point to 'Snapshot 1 Volume' on 'Source Domain' even if the real swap happens in the next step.

[[Image:StorageLiveMigrationAPIDiagram1.png]]

===Limitations and Risks===
* VDSM doesn't have the proper metadata to describe a VM running on volumes stored on two different storage domains
* missing libvirt operation to change the volume backing file on the fly, new design and patches:
** https://www.redhat.com/archives/libvir-list/2012-January/msg01448.html
** https://www.redhat.com/archives/libvir-list/2012-February/msg00014.html

===Engine Flow===
[http://en.wikipedia.org/wiki/Pseudocode Pseudocode]

 def vm_live_block_migrate(vm, destDomain):
     for drive in vm_get_drives(vm):
         createVolumeCrossSD(drive) # to the SPM
 
     # Retry until it succeed or fails with a known error
     while True:
         ret = blockMigrate(driveParams) # to the HSM
         if ret == SUCCESS
             break
         elif ret == VM_NOT_RUNNING:
             # rollback the createVolumeCrossSD operations
             return VM_NOT_RUNNING
 
     for drive in vm_get_drives(vm):
         while True:
             ret = cloneInternalVolumes(drive)
             if ret == SUCESS:
                 break
 
     finalizeBlockMigrate() # to the HSM

==Mirrored-Snapshot Execution Diagrams and Description==

[[Image:StorageLiveMigration2.png]]

[[Image:StorageLiveMigrationAPIDiagram2.png]]

===VDSM API===
The command <code>copyVolume(...)</code> is used in step 2 and 4 to copy the volumes from the source to the destination. For maximum flexibility it's possible to change the volume and image UUIDs (on the destination) and update the parent volume UUID (so that it's possible to rebuild a consistent chain on the destination).

 def copyVolume(srcDomUUID, dstDomUUID, srcImgUUID, dstImgUUID,
                srcVolUUID, dstVolUUID, dstBakImgUUID, dstBakVolUUID):
     """
     Copies a single volume from a source (domain, image, volume) to a new
     destination (domain, image, volume).
 
     If dstBakVolUUID is specified it will be used to rebase (unsafe) the
     volume (if dstBakImgUUID is not specified, dstImgUUID will be used).
 
     If dstBakVolUUID is not specified and the source volume has a parent,
     then the same srcImgUUID and srcVolUUID will be reused.
 
     :param srcDomUUID: The source storage domain UUID
     :type srcDomUUID: UUID
     :param dstDomUUID: The destination storage domain UUID
     :type dstDomUUID: UUID
     :param srcImgUUID: The source image UUID
     :type srcImgUUID: UUID
     :param dstImgUUID: The destination image UUID
     :type dstImgUUID: UUID
     :param srcVolUUID: The source volume UUID
     :type srcVolUUID: UUID
     :param dstVolUUID: The destination volume UUID
     :type dstVolUUID: UUID
     :param dstBakImgUUID: The new backing image UUID for the destination
                           (optional parameter)
     :type dstBakImgUUID: UUID
     :param dstBakVolUUID: The new backing volume UUID for the destination
                           (optional parameter)
     :type dstBakVolUUID: UUID
     """

===Engine Flow===
Initial notes:

* take a snapshot of a single disk (step 3)
* mark "Snapshot 1" (old leaf) as MERGE_PENDING
* mark "Snapshot 2" (new leaf) with the same SNAPSHOT_ID of "Snapshot 1" (NB. do '''not''' mark with MERGE_PENDING)

==Pre-Copy Execution Diagrams and Description==

[[Image:StorageLiveMigration3.png]]

The following

===REST API===
The REST API should take advantage of the "update" command for a VM disk, specifying the new storage domain.

 <link href="/api/vms/{vm:id}/disks/{disk:id}" rel="update"/>
 
 POST /api/vms/{vm:id}/disks/{disk:id} HTTP/1.1
 Accept: application/xml
 Content-type: application/xml
 
 <disk>
     <storage_domains>
         <storage_domain id="{storage_domain:id}"/>  
     </storage_domains>    
 </disk>

===Engine Flow===
Pseudocode (work in progress):

 def storageLiveMigration(spmHost, vmHost):
     # Start moving the image to the destination (leaf not included)
     spmTask = spmHost.moveImage(spUUID, srcDomUUID, dstDomUUID, imgUUID, None, LIVECOPY_OP)
 
     # Wait for the empty leaf to appear on the destination
     while True:
         status = spmHost.getTaskStatus(spmTask)
 
         # If the task got interrupted try to delete the image on the destination and fail
         if status != Running:
             spmHost.deleteImage(spUUID, dstDomUUID, imgUUID)
             raise FailureException
 
         # Check that the new leaf has been created on the destination
         status = spmHost.getVolumeInfo(spUUID, dstDomUUID, imgUUID, leafUUID)
         if status == Done:
             break
 
         # Timeout?
 
     # Initiate the block migration in qemu-kvm
     hsmTask = vmHost.blockMigrateStart(vmUUID, {
         "srcDomUUID": srcDomUUID,
         "dstDomUUID": dstDomUUID,
         "imgUUID":    imgUUID,
     })
 
     # Wait for both the spm copy and the hsm copy/mirroring to finish
     while True:
         spmStatus = spmHost.getTaskStatus(spmTask)
         hsmStatus = hsmHost.getBlockMigrateStatus(vmUUID, hsmTask)
 
         if spmStatus == Done and hsmStatus == Done:
             break
 
         if spmStatus == Failure or hsmStatus == Failure:
             # FIXME: we probably need more here
 
             # Reopen the leaf only on the source
             vmHost.blockMigrateEnd(vmUUID, hsmTask, srcDomUUID)
             spmHost.deleteImage(spUUID, dstDomUUID, imgUUID)
 
             raise FailureException
 
     # Finalize the migration to the destination
     vmHost.blockMigrateEnd(vmUUID, hsmTask, dstDomUUID)

===VDSM SPM===

Add a new moveImage operation: '''LIVECOPY_OP''' (0x03)

 moveImage(spUUID, srcDomUUID, dstDomUUID, imgUUID, vmUUID, op, postZero=False, force=False)

* '''spUUID:''' storage pool UUID
* '''srcDomUUID:''' source domain UUID
* '''dstDomUUID:''' destination domain UUID
* '''imgUUID:''' image UUID (it will be maintained on the destination)
* '''vmUUID:''' unused
* '''op:''' must be LIVECOPY_OP (0x03)
* '''postZero:''' unused
* '''force:''' unused

Description of '''LIVECOPY_OP''':

* it copies all the volumes up to the leaf (not included)
* it prepares an empty volume for the leaf on the destination
* it doesn't automatically rollback (because the SPM doesn't know if the qemu-kvm process is already mirroring the new leaf)

===VDSM HSM===
Add a new '''blockMigrate''' command:

 blockMigrate(vmUUID, blkMigParams)

The only format supported for '''blkMigParams''' at the moment is:

 blkMigParams = {
     "srcDomUUID": "<srcDomUUID>",
     "dstDomUUID": "<dstDomUUID>",
     "imgUUID":    "<imgUUID>",
 }

* '''vmUUID:''' VM UUID
* '''srcDomUUID:''' source domain UUID
* '''dstDomUUID:''' destination domain UUID
* '''imgUUID:''' image UUID (it will be maintained on the destination)

Which relies on the libvirt function virDomainBlockRebase:

 virDomainBlockRebase(dom, disk, "/path/to/copy",
     VIR_DOMAIN_BLOCK_REBASE_COPY | VIR_DOMAIN_BLOCK_REBASE_SHALLOW |
     VIR_DOMAIN_BLOCK_REBASE_REUSE_EXT)

This call assumes that '''/path/to/copy''' is already present (and initialized) and only the leaf content will be streamed to the new destination (no squashing).
