<!-- {{autolang|base=yes}} -->

== NUMA and Virtual NUMA ==

=== Summary ===
This feature allow Enterprise customers to provision large guests for their traditional scale-up enterprise workloads and expect low overhead due to visualization.
* Query target host’s NUMA topology
* NUMA bindings of guest resources (vCPUs & memory)
* Virtual NUMA topology
You may also refer to the [http://www.ovirt.org/Features/NUMA_and_Virtual_NUMA simple feature page].

=== Owner ===
* Name: [[User:JasonLiao| Jason Liao]], [[User:BruceShi| Bruce Shi]]
* Email: [mailto:chuan.liao@hp.com chuan.liao@hp.com], [mailto:xiao-lei.shi@hp.com xiao-lei.shi@hp.com]
*IRC: jasonliao, bruceshi @ #ovirt (irc.oftc.net)

=== Current status ===
* Target Release: oVirt 3.5
* Status: design
* Last updated: 25 Mar 2014
This is the detailed design page for NUMA and Virtual NUMA

=== Data flow diagram ===
[[File:Data_Flow_Diagram.png]]

=== Interface & data structure ===
==== Interface between VDSM and libvirt ====
# I-1.1  Host's NUMA node index and CPU id of each NUMA node
# I-1.2  Host's NUMA node memory information, include total and free memory
# I-1.5  Configuration of VM's memory allocation mode and memory comes from which NUMA nodes
# I-1.6  Configuration of VM's virtual NUMA topology

* I-1.1 Seek the host NUMA nodes information by using <code>getCapabilities</code> API in libvirt
<pre>
<capabilities>
    …
    <host>
        ...
        <topology>
            <cells num='1'>
                <cell id='0'>
                    <cpus num='2'>
                        <cpu id='0'/>
                        <cpu id='1'/>
                    </cpus>
                </cell>
      </cells>
        </topology>
        …
    </host>
    …
</capabilities>
</pre>

* I-1.2 Seek the host NUMA nodes memory information by using <code>getMemoryStats</code> API in libvirt, the below is the data format of API returned value
<pre>
{ total: int, free: int }
</pre>

* I-1.5 Create a new function <code>appendNumaTune</code> in VDSM vm module to write the VM numatune configuration into libvirt domain xml follow the below format
<pre>
<domain>
    ...
    <numatune>
        <memory mode='interleave' nodeset='0-1'/>
    </numatune>
    …
</domain>
</pre>

* I-1.6 Modify function <code>appendCpu</code> in VDSM vm module to write the VM virtual NUMA topology configuration into libvirt domain xml follow the below format
<pre>
<cpu>
    ...
    <numa>
      <cell cpus='0-7' memory='10485760'/>
      <cell cpus='8-15' memory='10485760'/>
    </numa>
    ...
</cpu>
</pre>

==== Interface between VDSM and Host ====
# I-1.3 Statistics data of each host CPU core which include %usr (%usr+%nice), %sys and %idle.
# I-1.4 Data structure to be provided to MOM component
# I-1.7 NUMA distances capture from command
# I-1.8 Automatic NUMA balancing on host

* I-1.3 Sampling host CPU statistics data in <code>/proc/stat</code>, the whole data format is showing as below. We will use column 1 to 5 which include user, system, nice and idle CPU handlers to calculate CPU statistics data in engine side
<pre>
$ cat /proc/stat
cpu  268492078 16093 132943706 6545294629 19023496 898 138160 0 57789592
cpu0 62042038 3012 52198814 1638619972 2438624 4 12068 0 16721375
cpu1 62779520 2733 25830756 1647361083 6001324 1 34617 0 16341547
cpu2 77892630 5788 32963856 1610093241 8367287 889 80447 0 8205583
cpu3 65777888 4559 21950279 1649220333 2216260 4 11027 0 16521086
</pre>

* I-1.4 Data structure that provided to MOM component
MOM use the VDSM HypervisorInterface
using API.py <code>Global.getCapabilities</code> function to get host NUMA topology data
<pre>
'autoNumaBalancing': int
'numaDistances': {'<nodeIndex>': [int], ...}
'numaNodes': {'<nodeIndex>': {'cpus': [int], 'totalMemory': int}, …}
</pre>
using API.py <code>Global.getStats</code> function to get host NUMA statistics data
<pre>
'numaNodeMemFree': {'<nodeIndex>': {'memFree': 'str'}, …}
'cpuStatistics': {'<cpuId>': {'nodeIndex': int, 'cpuSys': 'str', 'cpuIdle': 'str', 'cpuUser': 'str'}, …}
</pre>

* I-1.7 libivirt API do not support to get NUMA distances information, so we use command <code>numactl</code> to get the distances information
<pre>
$ numactl -H
node distances:
node   0   1 
  0:  10  20 
  1:  20  10
</pre>

* I-1.8 In kernels who having Automatic NUMA balancing feature, use command <code>sysctl -a |grep numa_balancing</code> to check the Automatic NUMA balancing value is turn on or off
<pre>
$ sysctl -a | grep numa_balancing
kernel.numa_balancing = 1
</pre>

==== Interface between VDSM and engine core ====
# I-2.1 Report host support automatic NUMA balancing situation, NUMA node distances, NUMA nodes information, include NUMA node index, cpu ids and total memory, from VDSM to engine core
# I-2.2 Report host NUMA nodes memory information (free memory and used memory percentage) and each cpu statistics (system, idle, user cpu percentage) from VDSM to engine core
# I-2.3 Configuration of set VM's numatune and virtual NUMA topology from engine core to VDSM
* I-2.1 Transfer data format of host NUMA nodes information
<pre>
'autoNumaBalancing': int
'numaDistances': {'<nodeIndex>': [int], ...}
'numaNodes': {'<nodeIndex>': {'cpus': [int], 'totalMemory': int}, …}
</pre>

* I-2.2 Transfer data format of host CPU statistics and NUMA nodes memory information
<pre>
'numaNodeMemFree': {'<nodeIndex>': {'memFree': 'str', 'memPercent': int}, …}
'cpuStatistics': {'<cpuId>': {'numaNodeIndex': int, 'cpuSys': 'str', 'cpuIdle': 'str', 'cpuUser': 'str'}, …}
</pre>

* I-2.3 Transfer data format of set VM numatune and virtual NUMA topology
<pre>
'numaTune': {'mode': 'str', 'nodeset': 'str'}
'guestNumaNodes': [{'cpus': 'str', 'memory': 'str'}, …]
</pre>

==== Interface between engine core and database (schema) ====
# I-3.1 Schema modification of <code>vds_dynamic</code> table to include host's NUMA node distance information, NUMA node count and automatic NUMA balancing support flag.
# I-3.2 Add table <code>vds_cpu_statistics</code> to include host cpu statistics information (system, user, idle cpu time and used cpu percentage)
# I-3.3 Add table <code>vds_numa_node_statistics</code> to include host NUMA node statistics information (system, user, idle cpu time, used cpu percentage, free memory and used memory percentage) 
# I-3.4 Schema modification of <code>vm_static</code> table to include NUMA type, numatune mode configuration and virtual NUMA node count
# I-3.5 Add table <code>vds_numa_node</code> to include host NUMA node information (node index, total memory, cpu count of each node, cpu list of each node)
# I-3.6 Add table <code>vm_numa_node</code> to include vm virtual NUMA node information (node index, total memory, vCPU count of each node, vCPU list of each node)
# I-3.7 Add table <code>vm_numatune_nodeset</code> to include vm numatune nodeset configuration (this is a relationship table, store the map relations between vm and <code>vds_numa_node</code>)
# I-3.8 Add table <code>vm_vds_numa_node_map</code> to include the configuration of vm virtual NUMA nodes pinning to host NUMA nodes (this is a relationship table, store the map relations between <code>vm_numa_node</code> and <code>vds_numa_node</code>)
The above interfaces are defined with database design diagram
[[File:Database_design_diagram.png]]
* Related database scripts change:
*# Add <code>numa_sp.sql</code> to include the store procedures which handle the operations in table <code>vm_numa_node</code>, <code>vds_numa_node</code>, <code>vm_numatune_nodeset</code>, <code>vds_numa_node_statistics</code> and <code>vm_vds_numa_node_map</code>. It will provide the store procedures to insert, update and delete data and kinds of query functions.
*# Modify <code>vds_sp.sql</code> to add some store procedures which handle the operations in table <code>vds_cpu_statistics</code>, including insert, update, delete and kinds of query functions.
*# Modify the function of <code>InsertVdsDynamic</code>, <code>UpdateVdsDynamic</code> in <code>vds_sp.sql</code> to add new columns <code>auto_numa_banlancing</code>, <code>numa_node_distance_list</code> and <code>vds_numa_node_count</code>.
*# Modify the function of <code>InsertVmStatic</code>, <code>UpdateVmStatic</code> in <code>vms_sp.sql</code> to add three new columns <code>numa_manual_binding</code>, <code>numatune_mode</code> and <code>vm_numa_node_count</code>.
*# Modify <code>create_views.sql</code> to add new columns <code>numa_manual_binding</code>, <code>numatune_mode</code> and <code>vm_numa_node_count</code> in view <code>vms</code>; add new columns <code>auto_numa_banlancing</code>, <code>numa_node_distance_list</code> and <code>vds_numa_node_count</code> in view <code>vds</code>.
*# Modify <code>create_views.sql</code> to add new views, including view <code>vds_numa_node_view</code> which joins <code>vds_static</code>, <code>vds_numa_node</code> and <code>vds_numa_node_statistics</code>; view <code>vm_numa_node_view</code> which joins <code>vm_static</code>, <code>vm_numa_node</code>; view <code>vm_numatune_nodeset_view</code> which joins <code>vm_static</code>, <code>vm_numatune_nodeset</code> and <code>vds_numa_node</code>; view <code>vm_vds_numa_node_view</code> which joins <code>vm_numa_node</code>, <code>vm_vds_numa_node_map</code> and <code>vds_numa_node</code>.
*# Modify <code>upgrade/post_upgrade/0010_add_object_column_white_list_table.sql</code> to add new columns <code>auto_numa_banlancing</code>, <code>numa_node_distance_list</code> and <code>vds_numa_node_count</code>.
*# Add one script under <code>upgrade/</code> to create tables - <code>vm_numa_node</code>, <code>vds_numa_node</code>, <code>vm_numatune_nodeset</code>, <code>vds_numa_node_statistics</code>, <code>vds_cpu_statistics</code>, <code>vm_vds_numa_node_map</code> and add columns in table <code>vds_dynamic</code> and <code>vm_static</code>.
*# Create the following indexes in the script mentioned in point 8:
*#* Index on column <code>vm_guid</code> of table <code>vm_numa_node</code>
*#* Index on column <code>vds_numa_node_count</code> of table <code>vds_dynamic</code>
*#* Indexes on each of the columns <code>vm_guid</code> and <code>vds_numa_node_id</code> of table <code>vm_numatune_nodeset</code>
*#* Indexes on each of the columns <code>vds_id</code> and <code>cpu_count</code> of table <code>vds_numa_node</code>
*#* Indexes on each of the columns <code>vds_id</code> and <code>vds_numa_node_id</code> of table <code>vds_cpu_statistics</code>
*#* Indexes on each of the columns <code>vm_numa_node_id</code> and <code>vds_numa_node_id</code> of table <code>vm_vds_numa_node_map</code>
*# Modify <code>create_views.sql</code> to add new columns <code>auto_numa_balancing</code> and <code>numa_node_distance_list</code> in view <code>vds_with_tags</code>.

* Related DAO change:
*# Add <code>VdsNumaNodeDAO</code> and related implemention to provide data save, update, delete and kinds of queries in table <code>vds_numa_node</code> and <code>vds_numa_node_statistics</code>. Add <code>VdsNumaNodeDAOTest</code> for <code>VdsNumaNodeDAO</code> meanwhile.
*# Add <code>VmNumaNodeDAO</code> and related implemention to provide data save, update, delete and kinds of queries in table <code>vm_numa_node</code>. Add <code>VmNumaNodeDAOTest</code> for <code>VmNumaNodeDAO</code> meanwhile.
*# Add <code>VmNumatuneNodesetDAO</code> and related implemention to provide data save, update, delete in table <code>vm_numatune_nodeset</code> and queries to get vm configured VDS NUMA node which needs to join table <code>vm_static</code>,<code> vm_numatune_nodeset</code> and <code>vds_numa_node</code>. Add <code>VmNumatuneNodesetDAOTest</code> for <code>VmNumatuneNodesetDAO</code> meanwhile.
*# Add <code>VdsCpuStatisticsDao</code> and related implementation to provide data save, update, delete and kinds of queries in table <code>vds_cpu_statistics</code>. Add <code>VdsCpuStatisticsDAOTest</code> for <code>VdsCpuStatisticsDAO</code> meanwhile.
*# Modify <code>VdsDynamicDAODbFacadeImpl</code> and <code>VdsDAODbFacadeImpl</code> to add the map of new columns <code>auto_numa_banlancing</code>, <code>numa_node_distance_list</code> and <code>vds_numa_node_count</code>. Run <code>VdsDynamicDAOTest</code> to verify the modification.
*# Modify <code>VmStaticDAODbFacadeImpl</code> and <code>VmDAODbFacadeImpl</code> to add the map of new columns <code>numa_type</code>, <code>numatune_mode</code> and <code>numa_node_count</code>. Run <code>VmStaticDAOTest</code> to verify the modification.
*# Add <code>VmNumaNodeMapDAO</code> and related implemention to provide data save, update, delete in table <code>vm_vds_numa_node_map</code> and queries about the relationship between <code>vm_numa_node</code> and <code>vds_numa_node</code> which needs to join table <code>vm_numa_node</code>, <code>vm_vds_numa_node_map</code> and <code>vds_numa_node</code>. Add <code>VmNumaNodeMapDAOTest</code> for <code>VmNumaNodeMapDAO</code> meanwhile.

* Related search engine change
Currently, we plan to provide below search functions about NUMA feature, each field support the numeric relation of “>”, “<”, “>=”, “<=”, “=”, “!=”.
# Search hosts with the below NUMA related fields:
#* NUMA node number
#* NUMA node cpu count
#* NUMA node total memory
#* NUMA node memory usage
#* NUMA node cpu usage
# Search vms with the below NUMA related fields:
#* Manual NUMA binding
#* NUMA tune mode
#* Virtual NUMA node number
#* Virtual NUMA node vcpu count
#* Virtual NUMA node total memory
# Manual NUMA binding and NUMA tune mode support enum value relation, the others support the numeric relation.
#* Modify <code>org.ovirt.engine.core.searchbackend.SearchObjects</code> to add new entry NUMANODES and VIRTUALNUMANODES.
#* Add <code>org.ovirt.engine.core.searchbackend.NumaNodeConditionFieldAutoCompleter</code> to provide NUMA node related filters auto completion; 
#* Add <code>org.ovirt.engine.core.searchbackend.VirtualNumaNodeConditionFieldAutoCompleter</code> to provide virtual NUMA node related filters auto completion.
#* Modify <code>org.ovirt.engine.core.searchbackend.SearchObjectAutoCompleter</code> to add new joins, one is  HOST joins NUMANODES on vds_id, the other is VM joins VIRTUALNUMANODES on vm_guid. 
#* Add new entries in entitySearchInfo accordingly. NUMANODES will use new added view  vds_numa_node_view and VIRTUALNUMANODES will use new added view vm_numa_node_view.
#* Modify <code>org.ovirt.engine.core.searchbackend.VdsCrossRefAutoCompleter</code> to add auto complete  entry NUMANODES; Modify <code>org.ovirt.engine.core.searchbackend.VmCrossRefAutoCompleter</code> to  add auto complete entry VIRTUALNUMANODES.

==== Interface and data structure in engine core ====
[[File:ARCH Class Diagram.png]]
*Entities
** <code>VDS</code> has many <code>VdsNumaNode</code> objects in dynamic data (collect from vds capatibility)
** <code>VdsNumaNode</code> is core entity for host NUMA topology, it links one statistics object <code>VdsNumaNodeStatistics</code> which contains some real-time data (free memory, NUMA node cpu usage etc.)
** <code>VM</code> has many <code>VmNumaNode</code> object in dynamic data (configured by user)
** <code>VmNumaNode</code> is core entity for VM NUMA topology. 
** <code>NumaTuneMode</code> is the memory tune mode (configured by user).
** <code>VdsNumaNode</code> has one-to-many relationship with <code>VmNumaNode</code>.
** <code>VdsNumaNode.cpuIds</code> links with <code>CpuStatistics.cpuId</code> to take a look inside NUMA node each CPU usage
* Action & Query
** <code>GetVdsNumaNodeByVdsId, GetVmNumaNodeByVmId, GetVmNumaNodeByVdsNumaNodeId, GetCpuStatsByVdsId</code> use same parameters <code>IdQueryParameters</code>
** <code>AddVmNumaNode, UpdateVmNuamNode, RemoveVmNuamNode</code> use same parameters <code>VmNumaNodeParameters</code> to manage Virtual NUMA node in VM
** <code>SetNumaTuneMode</code> use parameters <code>NumaTuneModeParameters</code> to set the NUMA tuning mode for VM
** <code>GetVdsNumaNodeByVdsId</code> will return List<VdsNumaNode>
** <code>GetVmNumaNodeByVmId, GetVmNumaNodeByVdsNumaNodeId</code> will return List<VmNumaNode>
** <code>GetVmNumaNodeByVdsNumaNodeId</code> will query the <code>VmNumaNode</code>s under the <code>VdsNumaNode</code>
** <code>GetCpuStatsByVdsId</code> will return List<CpuStatistics>
** When <code>VmNumaNodeParameters.vdsNumaNodeId</code>  is set to null, the VmNumaNode is unsigned.

==== Interface and data structure in ovirt scheduler ====
Add NUMA filter and weight module to oVirt's scheduler, and add those to all cluster policies (inc. user defined).
* NUMA Filter
** Fetches the (scheduled) VM virutal NUMA nodes.
** Fetches all virtual NUMA nodes topology ( CPU count, total memory ).
** Fetches all hosts NUMA nodes topology ( CPU count, total memory ).
** Remove all hosts that doesn't meet the matched NUMA nodes topology
*** for positive, host NUMA node's CPU count > virtual NUMA node's CPU count
*** for positive, host NUMA node's total memory > virtual NUMA node's total memory
* NUMA Weight Module
** Fetches the (scheduled) VM virutal NUMA nodes.
** Fetches all virtual NUMA nodes topology ( CPU count, total memory, NUMA distance ).
** Fetches all hosts NUMA nodes topology and statistics ( CPU usage, free memory ).
** Score the hosts according to each NUMA nodes score
*** for positive, in case a VM of the group is running on a certain host, give all other hosts a higher weight.
*** for positive, give the host higher weight if the host NUMA node's CPU usage use up.
*** for positive, give the host higher weight if the host NUMA node's memory use up.
Scheduler generate virtual NUMA topology
To be continue ...

==== Interface and data structure in restful API ====
host NUMA sub-collection
<pre>
/api/hosts/{host:id}/numanodes/
</pre>
*Supported actions - '''GET''' returns a list of host NUMA nodes. (using query GetVdsNumaNodeByVdsId)
host NUMA resource
<pre>
/api/hosts/{host:id}/numanodes/{numa:id} 
</pre>
*Supported actions
**'''GET''' returns a specific NUMA node information: CPU list, total memory, map of distance with other nodes. (using VdsNumaNode properties)
host NUMA statistics
<pre>
/api/hosts/{host:id}/numanodes/{numa:id}/statistics
</pre>
*Supported actions
**'''GET''' returns a specific NUMA node statistics data: CPU usage, free memory.  (using VdsNumaNode  property NumaNodeStatistics)
vm virtual NUMA sub-collection
<pre>
/api/vms/{vm:id}/numanodes 
</pre>
*Supported actions: 
**'''GET''' returns a list of VM virtual NUMA nodes. (using query GetVmNumaNodeByVmId)
**'''POST''' attach a new virtual NUMA node on VM. (using action AddVmNumaNode)
vm virtual NUMA resource
<pre>
/api/vms/{vm:id}/numanodes/{vnuma:id}
</pre>
*Supported actions: 
**'''GET''' returns a specific virtual NUMA node information, CPU list, total memory, pin to host NUMA nodes.   (using VmNumaNode properties)
**'''PUT''' update a virtual NUMA node configured on the VM.  (using action UpdateVmNumaNode)
**'''DELETE''' removes a virtual NUMA node from the VM. (using action DeleteVmNumaNode)
